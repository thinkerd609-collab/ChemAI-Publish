5. Challenges, Limitations & Green Analytical Chemistry Perspective
5.1 Matrix Effects and Spectral Interference in Complex Environmental Samples
Complex environmental matrices impose spectral interferences on Raman and FTIR measurements that fundamentally limit classifier performance in ways that laboratory benchmarking on pristine polymer libraries does not capture. The most consequential interference categories are biogenic co-extractants, mineral matrix phases, and dissolved or particulate organic matter—each of which deposits characteristic spectral signatures that overlap with diagnostic polymer bands and systematically degrade classification accuracy. In wastewater and river water matrices with high biochemical oxygen demand, co-extracted humic and fulvic acids contribute broad Raman fluorescence backgrounds and diffuse FTIR absorption features across the 1000–1800 cm⁻¹ fingerprint region, directly obscuring the C–C skeletal stretching modes of PE and PP and the carbonyl bands of PET (Smolen et al., 2025). Surfactant residues in wastewater effluent introduce carbonyl and ether C–O bands that the RF classifier of Smolen et al. (2025) could not distinguish from polymer absorption features without explicit spectral subtraction, yielding an accuracy of only 83%—the lowest single-matrix result in the case-study literature reviewed—and underscoring that matrix-informed preprocessing is not a post-hoc refinement but an integral component of analytical method development.
In sediment matrices, biofouling of particle surfaces by bacterial biofilms introduces protein amide I (~1650 cm⁻¹) and amide II (~1540 cm⁻¹) bands, polysaccharide ring-breathing modes (~1030 cm⁻¹), and lipid C–H stretches that can reduce polymer-band peak heights by 30–60% relative to clean particle surfaces while simultaneously generating new bands diagnostic of biological rather than synthetic material (Cabot et al., 2024). Enzymatic pre-treatment with proteinase K and cellulase substantially reduces biofilm interference but is incomplete for thick or mineralogically encrusted biofilms, and the chemical oxidants (H₂O₂, Fenton reagent) used as alternatives selectively degrade surface functional groups of susceptible polymers—particularly PET ester linkages and PVC chlorinated domains—generating precisely the spectral drift that classifiers trained on untreated particles cannot accommodate. In the high-organic-load industrial wastewaters characteristic of textile dyeing operations in Pakistan's Punjab province, reactive dye adsorption onto polyester fibre surfaces introduces chromophore-derived Raman bands and spurious carbonyl absorptions in FTIR spectra that Khanam et al. (2025) identified as the primary driver of misclassification in their XGBoost classifier, with a 14-percentage-point accuracy improvement achievable only after explicit dye-correction preprocessing—a finding that argues strongly for matrix-specific model development rather than universal polymer classifiers.
5.2 Small Particle Size Bias and Nanoplastic Detection Limits
The analytical invisibility of sub-10-μm particles in standard Raman and FTIR workflows represents what is arguably the most consequential unresolved bias in the microplastics field. Particles below the diffraction-limited spatial resolution of ATR-FTIR (~10–20 μm) are physically inaccessible to standard FTIR imaging, meaning that abundance estimates derived from FTIR counting systematically exclude a size fraction that constitutes the numerical majority of microplastic particles in most environmental matrices (Zhu et al., 2025). For Raman spectroscopy, confocal systems can in principle access the 1–10 μm size range, but acquisition times per particle increase dramatically at smaller sizes—from seconds at 20 μm to minutes at 2 μm—due to declining signal-to-noise ratios, fluorescence background dominance, and the risk of laser-induced photodegradation at the high power densities required to obtain interpretable spectra from nanoscale volumes (Sunil et al., 2025). The practical consequence is that automated high-throughput Raman mapping pipelines, which are the principal vehicle for ML-based abundance surveys, invariably apply minimum particle size thresholds of 10–20 μm that exclude the size fractions of greatest toxicological concern.
For true nanoplastics (< 1 μm), neither conventional Raman nor FTIR spectroscopy is analytically viable without signal enhancement. Surface-enhanced Raman spectroscopy (SERS) using gold or silver nanoparticle substrates provides electromagnetic field enhancements of 10⁶–10⁸-fold that in principle enable single-particle detection at the nanoscale, but substrate batch-to-batch reproducibility—typically expressed as a relative standard deviation in enhancement factor of 20–40%—renders quantitative SERS inadequate for the concentration measurements demanded by environmental monitoring (Sunil et al., 2025). Nano-FTIR and AFM-IR techniques couple atomic force microscopy with infrared spectroscopy to achieve spatial resolution of 10–50 nm, but with acquisition rates of minutes to hours per particle and field-of-view areas of a few square micrometres, their throughput is incompatible with the analysis of heterogeneous environmental samples containing thousands of particles per filter. Li et al. (2026) noted that sub-5-μm particles constituted over 60% of total particle count in atmospheric deposition samples but less than 5% of total estimated particle mass—a finding that illustrates the fundamental tension between number-weighted and mass-weighted abundance metrics and highlights the need for orthogonal quantitative methods such as pyrolysis-GC-MS for mass-based nanoplastic characterization.
5.3 Instrument and Model Generalizability Issues
A defining structural weakness of the current ML-spectroscopy literature is the near-universal absence of external validation: the overwhelming majority of published models are evaluated on test sets drawn from the same spectral library or sampling campaign as the training data, with no independent assessment on spectra collected by a different laboratory, instrument model, or field campaign. Instrument-to-instrument variability—encompassing wavenumber calibration offsets of ±1–3 cm⁻¹, detector quantum efficiency differences, laser wavelength drift, and optical throughput variations—generates systematic spectral shifts that translate into classification accuracy penalties of 8–15 percentage points when a model trained on one spectrometer is applied to spectra from another (Khanam et al., 2025; Smolen et al., 2025). This instrument transfer problem is particularly acute for portable FTIR devices, whose reduced optical path length, lower detector sensitivity, and fixed ATR crystal geometry produce spectra with systematically lower SNR and altered relative band intensities compared to benchtop ATR-FTIR references.
Model generalizability is further compromised by the polymer class distribution imbalance endemic to environmental microplastic datasets: PE and PP typically constitute 50–70% of particle counts in freshwater and terrestrial samples, while specialty polymers (polycarbonate, polyurethane, ethylene-vinyl acetate copolymers) represent fewer than 2–5% of particles but are environmentally relevant as sources of toxic additives and degradation products. Classifiers trained on such imbalanced datasets learn decision boundaries heavily biased toward the majority classes, producing high overall accuracy figures that mask poor sensitivity for minority polymer types (Zhang et al., 2025). Oversampling (SMOTE), class-weighted loss functions, and metric learning approaches partially mitigate this imbalance, but these techniques have not been systematically benchmarked against environmental samples with independently verified polymer compositions, leaving their real-world efficacy uncertain.
5.4 Data Scarcity, Open Datasets, and Reproducibility Challenges
The absence of large, openly accessible, provenance-documented spectral libraries for environmental microplastics is the single most constraining infrastructural limitation for the development of robust, generalizable ML classifiers. Existing open repositories—Open Specy, SIFSAS, KnowItAll—contain predominantly pristine, additive-free polymer spectra, with limited coverage of weathered particles, co-polymers, pigment-containing formulations, and geographically diverse matrix backgrounds (Müller et al., 2025; Cabot et al., 2024). Individual laboratory datasets reported in the literature range from approximately 800 to 12,500 spectra—far below the tens of thousands of labeled examples required for reliable training of transformer and deep residual architectures without aggressive regularization—and are rarely deposited in accessible repositories, precluding independent reproduction of published accuracy claims or meta-analytic model comparison.
Reproducibility is further undermined by inconsistent reporting of methodological details: the specific spectral preprocessing pipeline (normalization, baseline correction algorithm, smoothing parameters), train/test split strategy (random split vs. stratified vs. leave-one-sample-out cross-validation), and hardware configuration are frequently omitted or inadequately described, making it impossible for readers to replicate results or assess the risk of data leakage between training and test sets. Zhang et al. (2025) highlighted that models evaluated by random spectral split—in which spectra of the same physical particle appear in both training and test sets—systematically overestimate generalization performance by 5–12% relative to leave-one-particle-out or leave-one-sample-out protocols that properly simulate independent sample deployment. The field lacks a minimum reporting standard analogous to the ARRIVE guidelines in life sciences or the FAIR data principles in data management, and the establishment of such a standard—covering spectral metadata, preprocessing provenance, data split rationale, and external validation requirements—is a prerequisite for cumulative scientific progress.
5.5 Green Analytical Chemistry Evaluation and Sustainability Aspects
The environmental footprint of the analytical workflows employed in microplastic characterization has received strikingly little systematic attention relative to the field's stated focus on environmental protection. A green analytical chemistry (GAC) evaluation framework—employing tools such as the AGREE assessment, the White Analytical Chemistry (WAC) score, or the Green Analytical Procedure Index (GAPI)—would assess workflows across dimensions including solvent consumption, energy demand, waste generation, sample throughput, and operator safety, yielding a standardized sustainability profile analogous to the accuracy metrics already routinely reported (Müller et al., 2025).
From a GAC perspective, TGA-FTIR analysis—despite its superior mass quantification performance—carries the highest environmental cost among the techniques reviewed: pyrolysis temperatures of 600–900 °C require substantial electrical energy per sample (estimated at 0.5–2 kWh per analytical run), evolved gas handling demands ventilation infrastructure, and the technique is inherently destructive, precluding archival retention of characterized samples for future re-analysis as methodological standards evolve (Müller et al., 2025). Density separation protocols employing ZnCl₂ or NaI solutions generate concentrated heavy metal or iodide waste streams requiring specialized disposal, and chemical digestion with Fenton reagent introduces iron waste and hydrogen peroxide hazards. By contrast, direct ATR-FTIR and Raman spectroscopy of pre-concentrated particles on membrane filters are intrinsically solvent-free, non-destructive, and energetically efficient—key attributes for GAC compliance—with the additional advantage of preserving sample integrity for complementary analyses.
The relevance of green analytical principles is particularly acute in the South Asian and Pakistani context, where laboratory infrastructure limitations constrain the availability of fume hoods, hazardous waste disposal services, and high-power instrumentation. The deployment of portable, battery-operated FTIR instruments—requiring no solvent, no specialized sample preparation, and minimal operator training—represents not merely an economic convenience but a direct alignment with GAC principles of accessibility, safety, and minimal environmental impact (Khanam et al., 2025; Cabot et al., 2024). However, the energy consumption of the GPU-based deep-learning inference pipelines that process field-collected spectral data—particularly transformer and ResNet architectures requiring cloud computing resources—represents an emerging sustainability concern whose carbon footprint has not been quantified in any of the reviewed studies, representing a gap that warrants explicit attention as ML model complexity continues to scale upward.
Table 7. Major challenges in ML-assisted spectroscopic microplastic analysis: current mitigation strategies and remaining methodological gaps.
Challenge	Affected Technique / ML Model	Impact on Accuracy	Mitigation Strategies	Remaining Gap
Biofouling and organic matrix interference	FTIR, Raman; SVM, RF, CNN	−10–15% vs. pristine baseline	Enzymatic digestion (proteinase K, cellulase); H₂O₂ oxidation; spectral baseline correction; domain-adapted retraining on biofouled spectra	Incomplete enzymatic digestion for complex biofilms; retraining datasets for biofouled particles remain scarce and non-standardized
Fluorescence background from organic matter / chromophores	Raman (all architectures); most severe at 532 nm	−8–12% SNR-dependent accuracy loss	NIR excitation (785, 1064 nm); photobleaching pre-irradiation; SERDS; polynomial or SNIP baseline algorithms	NIR shifts detection toward larger particles; 1064 nm reduces sensitivity for sub-10-μm particles; SERDS adds acquisition time
Photooxidative weathering and spectral drift	FTIR, Raman; 1D-CNN, SVM trained on pristine libraries	97% → 88% (pristine → field sediment)	Spectral augmentation with UV-aged and thermally degraded particles; TGA-FTIR to deconvolve carbonyl components; transfer learning from weathering-augmented pre-trained weights	No standardized weathering protocol for training augmentation; carbonyl-band overlap between oxidized PE and PET remains an unresolved misclassification source
Sub-10-μm and nanoplastic size bias	Raman (diffraction-limited mapping); FTIR (~10–20 μm floor); all count-based ML pipelines	> 60% by-count fraction undetected; mass estimates biased by ≤1 order of magnitude	SERS with Au/Ag nanoparticle substrates; nano-FTIR (AFM-IR); hyperspectral confocal Raman with sub-diffraction apertures; pyrolysis-GC-MS as orthogonal quantitative method	SERS substrate reproducibility inadequate for routine use; nano-FTIR/AFM-IR throughput is extremely low; no validated ML pipeline for SERS or pyrolysis-GC-MS data at environmental scale
Portable instrument spectral noise and resolution	Handheld FTIR; portable Raman; SVM, kNN (most affected)	−8–15% vs. benchtop baseline; field SNR 3× lower	Domain-adaptive transfer learning; instrument response function normalization; ensemble classifiers trained jointly on benchtop and portable spectra; data augmentation with additive Gaussian noise	Cross-instrument standardization protocols absent; no shared calibration reference material accepted across manufacturers for portable microplastic FTIR
Overfitting and small labeled dataset sizes	Deep CNN, Transformer, ResNet (all architectures)	5–15% accuracy inflation on in-distribution test sets vs. external validation	Dropout, weight decay, spectral data augmentation; few-shot / metric learning (Siamese, prototypical networks); cross-institutional dataset pooling; synthetic spectra from physical models	No open benchmark dataset with provenance-documented environmental spectra; external validation against independently collected samples rarely performed
Closed-set classifier assumption for unknown polymers	SVM, RF, kNN, 1D-CNN; any softmax-output classifier	Silent misclassification of unknowns; no uncertainty estimate	Metric / similarity learning (Siamese, prototypical networks); posterior probability thresholding; reject-option classifiers; conformal prediction intervals	Open-set accuracy rarely reported; no consensus threshold for ‘unknown’ rejection in environmental monitoring workflows; calibrated uncertainty quantification absent from most published models
Environmental impact of sample preparation and instrumentation	TGA-FTIR (high energy); density separation (ZnCl₂, NaI); H₂O₂ digestion; Fenton reagent	Sustainability cost not accuracy-related; WAC/AGREE scores unreported	Solvent-free ATR-FTIR and Raman as primary screening; aqueous density separation with recyclable NaCl; enzymatic digestion over chemical oxidation; miniaturized portable instruments reducing lab energy use	Systematic green metric (WAC, AGREE, GAPI) evaluation of full microplastic analytical workflows absent from literature; energy footprint of GPU-based deep learning inference not reported
SNR = signal-to-noise ratio; WAC = White Analytical Chemistry; AGREE = analytical greenness metric; GAPI = Green Analytical Procedure Index; SERS = surface-enhanced Raman spectroscopy; SERDS = shifted-excitation Raman difference spectroscopy; AFM-IR = atomic force microscopy infrared spectroscopy.

5.6 Transition to Future Directions
The challenges catalogued in this section are formidable but not intractable. The accuracy gap between pristine library performance and real environmental sample classification, the analytical invisibility of nanoplastics, the instrument generalizability deficit, the data scarcity and reproducibility crisis, and the unquantified sustainability footprint of complex analytical workflows each define a tractable research objective whose solution requires a coordinated combination of methodological innovation, infrastructure investment, and community standardization. Progress on these fronts is already visible in the transition from classical ML to domain-adaptive deep learning, in the early deployment of metric learning for open-set polymer identification, and in the growing recognition that portable instruments coupled to cloud-based ML classifiers offer a practical pathway to equitable global monitoring capacity. Translating these advances into robust, reproducible, and sustainably deployable analytical standards demands that the research community confront the limitations documented here with the same rigour that it applies to the development of new architectures—and that future work prioritizes external validation, open data deposition, green metric evaluation, and context-sensitive deployment design as first-class methodological obligations.
Addressing these fundamental challenges will require not only algorithmic innovation but a reimagining of how spectroscopic data are collected, shared, and validated across disciplines and geographies—themes that are explored in the following section on future directions for portable, sustainable, and globally equitable microplastic monitoring.
Disclaimer
All statements in this section are based exclusively on the cited references.
