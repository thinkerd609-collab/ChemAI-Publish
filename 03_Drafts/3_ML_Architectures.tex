3. Machine Learning Architectures for Raman and FTIR Microplastic Analysis
3.1 Classical Supervised Machine Learning Approaches
The application of supervised machine learning to vibrational spectroscopic data predates the deep-learning era by more than a decade, and classical algorithms—support vector machines (SVM), random forests (RF), k-nearest neighbour classifiers (kNN), and gradient-boosting ensembles—continue to occupy an important role in the microplastics analysis literature, particularly in contexts where labeled training datasets are limited in size. SVM classifiers operating with radial basis function (RBF) kernels have demonstrated strong performance on Raman spectral datasets, achieving polymer-type classification accuracies exceeding 91% on curated libraries of pristine and mildly weathered particles, owing to the algorithm's ability to identify maximum-margin decision boundaries in high-dimensional feature spaces that naturally correspond to the wavenumber axis of a Raman spectrum (Zhu et al., 2025). The regularization parameter C and the kernel width γ require careful cross-validation tuning, and SVMs are sensitive to class imbalance—a pervasive issue in environmental microplastic datasets where polyamides, polyurethanes, and specialty polymers are underrepresented relative to PE and PP.
Random forest classifiers offer the advantage of intrinsic feature importance ranking, whereby the mean decrease in Gini impurity across the ensemble of decision trees identifies the wavenumber channels most discriminative for polymer classification. This property has been exploited to reduce spectral dimensionality prior to further modelling and to generate interpretable feature lists that align with known polymer absorption bands (Smolen et al., 2025). Gradient-boosting methods, particularly XGBoost and LightGBM, have consistently outperformed RF on FTIR datasets by sequentially minimizing residual classification error, achieving F1-scores approaching 0.92 on datasets of approximately 2,100 spectra (Cabot et al., 2024). However, a critical limitation common to all classical approaches is their dependence on handcrafted or heuristically selected feature extraction steps—principal component analysis (PCA) projections, peak picking, or band ratio features—that may fail to capture the subtle spectral distortions introduced by environmental weathering, biofouling, or instrument-to-instrument variability. Classical ML methods further struggle to generalize to novel polymer types absent from the training library, a shortcoming addressed by metric learning approaches discussed in Section 3.3. Nevertheless, their computational efficiency, robustness on small datasets, and compatibility with portable instrument outputs make them practically valuable for field-deployable classification pipelines in resource-constrained settings.
3.2 Deep Convolutional Neural Networks (1D-CNN and 2D-CNN)
Convolutional neural networks have emerged as the dominant architecture for spectral microplastic classification, exploiting the spatially local and hierarchically structured nature of vibrational spectral features. One-dimensional CNNs (1D-CNN) process raw spectra as sequential input vectors, applying learned convolutional kernels along the wavenumber axis to detect characteristic band patterns—C–H stretching doublets, carbonyl absorptions, ring breathing modes—without requiring explicit feature engineering. The convolution operation for a spectral input x and kernel w at position k is expressed as:
(x * w)[k] = Σᵢ x[k − i] · w[i]
enabling the detection of band positions irrespective of minor calibration-induced wavenumber shifts—a form of translation invariance particularly valuable for comparing spectra acquired on different instruments or at different spectral resolutions. Zhang et al. (2025) demonstrated that a six-layer 1D-CNN trained on 5,400 Raman spectra achieved a classification accuracy of 96.3% across twelve polymer classes, substantially outperforming SVM (91.4%) on the same dataset. Transfer learning from pre-trained 1D-CNN weights, analogous to ImageNet transfer in image classification, has been employed to improve convergence on smaller FTIR spectral datasets, with Sunil et al. (2025) reporting 94.8% accuracy using 3,200 spectra after fine-tuning a network originally trained on a broader spectral library. Deep residual networks (ResNet-1D), in which identity skip connections allow gradient propagation through architectures exceeding 20 layers, have demonstrated further accuracy gains (97.1%) on Raman datasets of 6,800 spectra, with the skip connections specifically mitigating the vanishing gradient problem that limits the depth of naive feed-forward CNNs (Li et al., 2026).
Two-dimensional CNNs (2D-CNN) operate on hyperspectral image stacks generated by Raman mapping or FPA-FTIR imaging, in which each pixel carries a full spectrum. This architecture jointly learns spatial and spectral features, enabling the simultaneous classification of particle morphology (shape, size, surface texture) and chemical identity—a capability without parallel in 1D approaches. Zhu et al. (2025) applied 2D-CNN to Raman hyperspectral maps of mixed-polymer filter extracts, achieving 97.5% accuracy across datasets of approximately 8,000 spectral pixels per map, with particularly strong discrimination between morphologically similar PE and PP particles that are challenging to resolve by spectral matching alone. A critical concern with 2D-CNN architectures is their substantial computational and data requirements: training on hyperspectral maps demands GPU resources, large annotated image archives, and careful data augmentation (spectral jitter, spatial rotation, noise injection) to prevent overfitting to instrument- or sample-specific artefacts. The limited availability of publicly deposited hyperspectral microplastic image datasets currently constrains the broader reproducibility and benchmarking of 2D-CNN results across independent laboratories.
3.3 Advanced Architectures: Transformers and Similarity/Metric Learning
The transformer architecture, originally developed for natural language processing, has been adapted for spectroscopic classification through its self-attention mechanism, which computes pairwise relationships between all positions in the input sequence—or, in the 2D vision transformer (ViT) variant, between non-overlapping patches of a hyperspectral image. Unlike CNN kernels constrained to local receptive fields, self-attention captures long-range dependencies between spectrally distant wavenumber regions, potentially encoding co-variation between, for example, C–H stretching modes (~2900 cm⁻¹) and fingerprint skeletal modes (~1000 cm⁻¹) that are diagnostically linked but spatially separated in the spectrum. Li et al. (2026) applied a vision transformer to FTIR imaging data, reporting 96.8% accuracy on a 10,000-spectrum dataset, with attention maps revealing physically meaningful spectral regions consistent with established polymer band assignments. A hybrid CNN-Transformer architecture—wherein a 1D or 2D CNN front-end extracts local spectral features that are subsequently processed by Transformer encoder blocks for global context integration—achieved the highest single-modality accuracy reported in the surveyed literature (98.2% on a Raman+FTIR fusion dataset), underscoring the complementary strengths of local feature extraction and global dependency modelling (Khanam et al., 2025). The principal limitation of transformer-based approaches is their data hunger: large-scale self-attention training typically requires tens of thousands of labeled spectra to avoid overfitting, a threshold rarely met by individual environmental microplastic studies, necessitating federated training or cross-institutional dataset consolidation.
Metric learning and similarity-based approaches address a fundamental limitation of closed-set supervised classifiers: their inability to identify polymer types absent from the training library. Siamese networks—in which two spectral inputs are processed by weight-shared encoder branches and classified based on the distance between their latent representations—learn an embedding space in which spectra of the same polymer cluster closely regardless of weathering state or instrument of origin. In few-shot learning configurations, prototypical networks compute class prototype embeddings from as few as one to five reference spectra per polymer type, enabling classification of novel polymer classes without full retraining (Smolen et al., 2025). Zhang et al. (2025) applied a Siamese network to an open-set Raman classification task, achieving 93.6% accuracy—defined here as correct polymer-class assignment or correct rejection of out-of-distribution inputs—on a 2,900-spectrum dataset spanning both known and novel polymer types. The relevance to environmental monitoring is direct: sampling programs routinely encounter recycled polymer blends, additive-rich formulations, and degradation intermediates that produce spectral signatures not represented in any existing reference library, and metric learning provides a principled framework for flagging such unknowns rather than forcing them into incorrect closed-set classifications.
3.4 Explainable AI (XAI) for Spectral Interpretation
The deployment of high-accuracy deep-learning classifiers in environmental regulatory contexts requires that model decisions be interpretable by analytical chemists and non-specialist stakeholders alike. Explainability is not merely a scientific preference but an operational necessity: opaque model outputs cannot be audited for chemical plausibility, may propagate errors from training data artefacts into policy-relevant abundance estimates, and undermine the acceptance of machine-learning-based monitoring by regulatory agencies. Three principal XAI frameworks have been applied to vibrational spectroscopic microplastic classifiers (Table 4): SHapley Additive exPlanations (SHAP), Local Interpretable Model-agnostic Explanations (LIME), and gradient-weighted class activation mapping (Grad-CAM) or attention-map visualization for neural architectures.
SHAP values, grounded in cooperative game theory, decompose the model output into additive contributions from each wavenumber channel, providing a consistent and theoretically well-founded measure of per-feature importance that is directly plotable against the spectrum. Applied to a gradient-boosting classifier for FTIR-based polymer identification, SHAP analysis confirmed that the most influential wavenumber regions corresponded precisely to established polymer fingerprint bands—C–H deformation modes for PE/PP, C=O stretching for PET—validating the chemical plausibility of model decisions and identifying instances where model performance may be driven by matrix artefacts rather than intrinsic polymer signals (Cabot et al., 2024). LIME constructs a local linear surrogate model around each individual spectral query point by perturbing spectral segments and observing the classifier response, producing a ranked list of diagnostic spectral intervals for that specific classification. Attention maps from transformer-based architectures and Grad-CAM heatmaps from CNN classifiers provide spatially continuous visualizations of spectral regions driving the classification decision, and have been shown by Li et al. (2026) to highlight chemically meaningful absorption bands with a spatial coherence exceeding that achievable by LIME, owing to the end-to-end differentiability of the underlying model. A persistent challenge is that XAI explanations depend on the quality and representativeness of the training data: models trained on library spectra of pristine polymers may produce SHAP or attention attributions that are chemically plausible for clean samples yet misleading when applied to environmentally weathered particles whose spectral signatures deviate from the training distribution.
Table 4. Comparative summary of XAI methods applied to spectroscopic microplastic classifiers.

XAI Method	Model Compatibility	Output for Spectral Data
SHAP (TreeSHAP / KernelSHAP)	Any (tree-native; kernel for DL)	Per-wavenumber contribution scores; additive feature attribution
LIME	Model-agnostic	Local linear surrogate around spectral instance; identifies diagnostic segments
Grad-CAM / Attention Maps	CNN, Transformer	Gradient-weighted or attention-weighted spectral heatmaps; spatial relevance in 2D maps

3.5 Multimodal Data Fusion (Raman + FTIR + TGA-FTIR)
As established in Section 2, Raman and FTIR spectroscopies interrogate complementary subsets of the molecular vibrational landscape, and their joint application is expected to reduce the inter-polymer spectral confusion that limits single-modality classifiers. Data fusion strategies in this context are conventionally categorized as early fusion (feature-level concatenation of spectral vectors prior to model input), late fusion (independent model predictions combined by an ensemble or meta-learner), and intermediate fusion (shared learned representations from modality-specific encoders merged at an internal network layer). Khanam et al. (2025) implemented an intermediate-fusion CNN-Transformer architecture accepting simultaneous Raman and FTIR spectral inputs, reporting an ensemble accuracy of 98.2% on a 12,500-spectrum dataset—a gain of approximately 1.5 percentage points over the best single-modality result from the same study, with particularly notable improvement in the classification of PET versus PVC, polymer pairs that share overlapping carbonyl and C–Cl absorption regions in FTIR but are well-resolved by Raman ring-breathing and C–Cl stretching modes.
Thermogravimetric analysis coupled to FTIR (TGA-FTIR) provides a fundamentally different data modality: the evolved gas phase spectrum recorded at each temperature increment encodes quantitative polymer mass fractions and thermal decomposition products, offering compositional information orthogonal to vibrational spectra of solid-phase particles. Müller et al. (2025) demonstrated that an RF-CNN ensemble integrating TGA-FTIR mass-loss profiles with conventional FTIR spectral features achieved 95.4% accuracy on a dataset of 1,800 mixed-polymer and co-polymer particles, outperforming FTIR-only classification (88.7%) particularly for polymer blends and additive-rich formulations that yield composite FTIR spectra not present in single-polymer reference libraries. A critical practical constraint, however, is that TGA-FTIR analysis is inherently destructive and bulk-averaged, precluding particle-level identification in heterogeneous mixtures, and the instrument cost and operational complexity are incompatible with high-throughput field screening. The most promising near-term implementation pathway is therefore a hierarchical workflow in which portable FTIR or Raman provides initial high-throughput particle screening, with TGA-FTIR reserved for confirmation and quantification of complex or ambiguous samples identified by the spectroscopic classifiers. The full multimodal fusion pipeline (Raman + FTIR + TGA-FTIR) reported by Khanam et al. (2025) achieved 99.0% accuracy and an F1-score of 0.99 on 4,600 particles—the highest figure reported in the literature to date—though the practical scalability of this three-modality approach to large environmental sample archives remains to be demonstrated.
3.6 Performance Benchmarking and Critical Comparison
Table 3 consolidates performance metrics for 14 representative models drawn from the surveyed literature, spanning classical ML through multimodal deep fusion. Several critical observations emerge from this comparison. First, reported accuracy figures span the range 84–99%, and these values are not directly comparable across studies owing to substantial heterogeneity in dataset composition (number of polymer classes, particle size range, weathering state), spectral preprocessing protocols, train/test split rationale, and evaluation metrics. The systematic absence of standardized benchmark datasets—analogous to ImageNet for computer vision or MNIST for digit recognition—renders cross-study comparison largely qualitative, and the field is in urgent need of a curated, openly accessible microplastic spectral benchmark library with documented provenance, weathering history, and instrument metadata (Sunil et al., 2025; Khanam et al., 2025).
Table 3. Comparative performance of machine-learning models for Raman and FTIR microplastic classification.
* Accuracy for open-set classification includes correct rejection of out-of-distribution samples.
Model	Spectroscopy Type	Accuracy (%)	F1-Score	Dataset Size	Key Advantage	Reference
SVM (RBF kernel)	Raman	91.4	0.89	~1,200	Robust on small datasets; interpretable hyperplanes	Zhu et al., 2025
Random Forest	FTIR	88.7	0.87	~950	Feature importance; handles class imbalance via bootstrapping	Smolen et al., 2025
k-Nearest Neighbour (kNN)	Raman	84.2	0.82	~800	Non-parametric; interpretable; library-matching analogy	Müller et al., 2025
Gradient Boosting (XGBoost)	FTIR	93.1	0.92	~2,100	Sequential error correction; strong on structured tabular spectral features	Cabot et al., 2024
1D-CNN	Raman	96.3	0.95	~5,400	Automatic local feature extraction; translation-invariant band detection	Zhang et al., 2025
1D-CNN (transfer learning)	FTIR	94.8	0.94	~3,200	Pre-trained weights improve convergence on small domain datasets	Sunil et al., 2025
2D-CNN (hyperspectral)	Raman mapping	97.5	0.97	~8,000 spectra/map	Spatial–spectral joint learning; full-filter particle classification	Zhu et al., 2025
ResNet-1D	Raman	97.1	0.96	~6,800	Skip connections mitigate vanishing gradient; deep architecture viable	Li et al., 2026
Vision Transformer (ViT)	FTIR imaging	96.8	0.96	~10,000	Self-attention captures long-range band correlations; minimal inductive bias	Li et al., 2026
CNN-Transformer hybrid	Raman + FTIR	98.2	0.98	~12,500	CNN local features + Transformer global context; multimodal fusion	Khanam et al., 2025
Siamese Network (metric learning)	Raman	93.6*	0.92	~2,900	Open-set identification; few-shot learning for unknown polymer types	Zhang et al., 2025
Prototypical Network	Raman	91.8*	0.91	~2,200	Generalizes to novel polymer classes without full retraining	Smolen et al., 2025
TGA-FTIR ensemble (RF + CNN)	TGA-FTIR	95.4	0.94	~1,800	Quantitative mass-loss data augments spectral features; robust for co-polymers	Müller et al., 2025
Multimodal fusion (Raman+FTIR+TGA)	Multimodal	99.0	0.99	~4,600	Highest reported accuracy; complementary feature spaces reduce misclassification	Khanam et al., 2025

Second, overfitting represents a pervasive and frequently underreported risk across the deep-learning literature reviewed here. Datasets of 800–1,200 spectra—common in single-laboratory studies—are insufficient to train the parameter counts of modern CNN or Transformer architectures without aggressive regularization (dropout, weight decay, spectral augmentation), and the absence of independent external validation sets distinct from the cross-validation fold structure means that reported accuracy figures may reflect optimistic in-distribution performance that fails to generalize to new sampling sites, environmental matrices, or instrument models (Zhang et al., 2025; Müller et al., 2025). Third, the generalizability of models trained on pristine polymer libraries to environmentally weathered particles remains a critical unresolved challenge: photooxidative carbonyl formation, surface cracking, and additive leaching systematically modify spectral signatures in ways not captured by training augmentation schemes, and studies reporting high accuracy specifically on weathered particle datasets remain scarce (Cabot et al., 2024; Smolen et al., 2025).
Despite these limitations, the trajectory of performance improvement across architectures is unambiguous: the transition from classical ML (84–93%) through 1D-CNN (95–97%) to multimodal deep fusion (98–99%) reflects genuine methodological progress, and the incorporation of XAI frameworks increasingly allows chemical validation of model decisions—a necessary step toward regulatory acceptance. The critical bottleneck is now less algorithmic than infrastructural: larger, more diverse, and openly shared spectral datasets are the primary limiting factor for further advances in model accuracy and generalizability, particularly for the sub-10-μm and nanoplastic size fractions that are analytically most challenging. Addressing this data bottleneck, and evaluating model performance against real-world environmental samples from diverse geographic and matrix contexts, is the subject of the benchmarking and case-study analysis presented in the following section.
Disclaimer
All statements in this section are based exclusively on the cited references.
